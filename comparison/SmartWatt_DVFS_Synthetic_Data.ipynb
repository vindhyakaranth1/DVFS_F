{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0d6554",
   "metadata": {},
   "source": [
    "# Smart-Watt DVFS: ML-Based CPU Frequency Optimization\n",
    "\n",
    "## Implementation and Validation Using Synthetic Laptop Data\n",
    "\n",
    "This notebook demonstrates a complete implementation of predictive DVFS (Dynamic Voltage and Frequency Scaling) using machine learning.\n",
    "\n",
    "### Key Features Implemented:\n",
    "1. ‚úÖ **Temporal Windowing** - Uses last 5 CPU samples + deltas + statistics\n",
    "2. ‚úÖ **Horizon Prediction** - Predicts CPU load 1 second ahead (not current state)\n",
    "3. ‚úÖ **Random Forest Classifier** - 400 trees, depth 14, balanced classes\n",
    "4. ‚úÖ **Probability-Aware DVFS** - Uses ML confidence for decisions\n",
    "5. ‚úÖ **Hysteresis** - Prevents frequency oscillation (HOLD_HIGH=5, HOLD_LOW=3)\n",
    "6. ‚úÖ **Multi-Level Frequencies** - LOW (1520), MID (2000), HIGH (2400 MHz)\n",
    "7. ‚úÖ **Physics-Based Energy Model** - E = f¬≤ + Œ±¬∑|Œîf|¬∑f (accounts for transition costs)\n",
    "8. ‚úÖ **Baseline Comparison** - Quantifies energy savings vs traditional DVFS\n",
    "\n",
    "---\n",
    "\n",
    "**Dataset**: Synthetic laptop usage data (24 hours, 1-second resolution)  \n",
    "**Goal**: Predict optimal CPU frequency to minimize energy while maintaining performance  \n",
    "**Approach**: Smart-Watt predictive DVFS with temporal feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b1fc8b",
   "metadata": {},
   "source": [
    "## üì¶ Part 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ad3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn joblib -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")\n",
    "print(f\"   NumPy version: {np.__version__}\")\n",
    "print(f\"   Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload synthetic data (if using Colab)\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Define DATA_PATH from uploaded file\n",
    "DATA_PATH = list(uploaded.keys())[0]  # Get the name of the uploaded file\n",
    "\n",
    "# Load data\n",
    "print(\"üìÇ Loading synthetic laptop data...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded successfully!\")\n",
    "print(f\"   Total samples: {len(df):,}\")\n",
    "print(f\"   Duration: ~{len(df)/3600:.1f} hours\")\n",
    "print(f\"   Columns: {len(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview\n",
    "print(\"üìä Dataset Statistics:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüî¢ CPU Metrics:\")\n",
    "print(f\"   CPU Utilization: {df['cpu_percent'].min():.1f}% - {df['cpu_percent'].max():.1f}%\")\n",
    "print(f\"   Average CPU: {df['cpu_percent'].mean():.1f}%\")\n",
    "print(f\"   CPU Frequency: {df['cpu_freq_current'].min():.0f} - {df['cpu_freq_current'].max():.0f} MHz\")\n",
    "print(f\"   Average Frequency: {df['cpu_freq_current'].mean():.0f} MHz\")\n",
    "\n",
    "print(f\"\\nüíª System Metrics:\")\n",
    "print(f\"   Process Count: {df['process_count'].min()} - {df['process_count'].max()}\")\n",
    "print(f\"   Average Processes: {df['process_count'].mean():.0f}\")\n",
    "print(f\"   Memory Usage: {df['memory_percent'].min():.1f}% - {df['memory_percent'].max():.1f}%\")\n",
    "\n",
    "print(f\"\\nüîã Battery Status:\")\n",
    "charging_pct = (df['is_charging'].sum() / len(df)) * 100\n",
    "print(f\"   Charging time: {charging_pct:.1f}%\")\n",
    "print(f\"   On battery: {100-charging_pct:.1f}%\")\n",
    "\n",
    "print(f\"\\n‚è∞ Time Distribution:\")\n",
    "print(f\"   Weekday samples: {df['is_weekday'].sum():,} ({df['is_weekday'].mean()*100:.1f}%)\")\n",
    "print(f\"   Weekend samples: {(~df['is_weekday']).sum():,} ({(1-df['is_weekday'].mean())*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e28117e",
   "metadata": {},
   "source": [
    "## üìà Part 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CPU behavior over time\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "fig.suptitle('Laptop CPU Behavior Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: CPU Utilization over time (first 3600 samples = 1 hour)\n",
    "sample_range = min(3600, len(df))\n",
    "axes[0].plot(df['cpu_percent'][:sample_range], linewidth=0.8, alpha=0.7, color='steelblue')\n",
    "axes[0].axhline(y=df['cpu_percent'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"cpu_percent\"].mean():.1f}%', linewidth=2)\n",
    "axes[0].set_title('CPU Utilization Over Time (First Hour)', fontweight='bold', fontsize=12)\n",
    "axes[0].set_xlabel('Time (seconds)')\n",
    "axes[0].set_ylabel('CPU Utilization (%)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: CPU Frequency distribution\n",
    "axes[1].hist(df['cpu_freq_current'], bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[1].axvline(df['cpu_freq_current'].mean(), color='red', linestyle='--',\n",
    "                label=f'Mean: {df[\"cpu_freq_current\"].mean():.0f} MHz', linewidth=2)\n",
    "axes[1].set_title('CPU Frequency Distribution', fontweight='bold', fontsize=12)\n",
    "axes[1].set_xlabel('Frequency (MHz)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: CPU vs Process Count\n",
    "sample_for_scatter = df.sample(min(5000, len(df)))  # Sample for faster plotting\n",
    "scatter = axes[2].scatter(sample_for_scatter['cpu_percent'], \n",
    "                          sample_for_scatter['process_count'],\n",
    "                          alpha=0.3, s=10, c=sample_for_scatter['memory_percent'],\n",
    "                          cmap='viridis')\n",
    "axes[2].set_title('CPU Utilization vs Process Count (colored by Memory %)', \n",
    "                  fontweight='bold', fontsize=12)\n",
    "axes[2].set_xlabel('CPU Utilization (%)')\n",
    "axes[2].set_ylabel('Number of Processes')\n",
    "cbar = plt.colorbar(scatter, ax=axes[2])\n",
    "cbar.set_label('Memory %')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('01_raw_data_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üíæ Saved: 01_raw_data_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ffcd1",
   "metadata": {},
   "source": [
    "## üîß Part 3: Feature Engineering (Temporal Windowing)\n",
    "\n",
    "### Key Innovation: Temporal Features\n",
    "\n",
    "Instead of using just the current CPU value, we create **temporal features** that capture:\n",
    "- **Past behavior**: Last 5 CPU samples\n",
    "- **Rate of change**: Deltas between consecutive samples\n",
    "- **Statistical patterns**: Mean and standard deviation\n",
    "\n",
    "This transforms **1 feature ‚Üí 11 features** per sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_temporal_features(cpu_values, window=5):\n",
    "    \"\"\"\n",
    "    Build temporal features from CPU utilization time series.\n",
    "    \n",
    "    For each time step t, creates features from window [t-5, t-4, t-3, t-2, t-1]:\n",
    "    - Raw values: cpu[t-5], cpu[t-4], ..., cpu[t-1]\n",
    "    - Deltas: cpu[t-4]-cpu[t-5], cpu[t-3]-cpu[t-4], ...\n",
    "    - Statistics: mean, std\n",
    "    \n",
    "    Args:\n",
    "        cpu_values: Array of CPU utilization (0-100 scale)\n",
    "        window: Size of lookback window (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "        X: Feature matrix (n_samples - window, 11 features)\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    \n",
    "    for i in range(window, len(cpu_values)):\n",
    "        window_data = cpu_values[i - window:i]\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        # 1. Raw window values (5 features)\n",
    "        features.extend(window_data)\n",
    "        \n",
    "        # 2. Deltas - rate of change (4 features)\n",
    "        features.extend(np.diff(window_data))\n",
    "        \n",
    "        # 3. Statistics (2 features)\n",
    "        features.append(np.mean(window_data))  # Mean\n",
    "        features.append(np.std(window_data))   # Std deviation\n",
    "        \n",
    "        X.append(features)\n",
    "    \n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "def build_horizon_labels(cpu_values, window=5, horizon=5, threshold=30.0):\n",
    "    \"\"\"\n",
    "    Build horizon-based labels for PREDICTIVE frequency scaling.\n",
    "    \n",
    "    Key innovation: Instead of predicting current CPU state, we predict\n",
    "    the AVERAGE CPU over the next 'horizon' seconds. This allows the\n",
    "    DVFS system to scale UP frequency BEFORE load increases.\n",
    "    \n",
    "    Args:\n",
    "        cpu_values: Array of CPU utilization (0-100)\n",
    "        window: Feature window size\n",
    "        horizon: How many samples ahead to predict\n",
    "        threshold: CPU threshold for HIGH frequency (default: 30%)\n",
    "    \n",
    "    Returns:\n",
    "        y: Binary labels (1 = HIGH freq needed, 0 = LOW freq)\n",
    "    \"\"\"\n",
    "    y = []\n",
    "    \n",
    "    for i in range(window, len(cpu_values) - horizon):\n",
    "        # Look ahead 'horizon' samples and take average\n",
    "        future_avg = np.mean(cpu_values[i:i + horizon])\n",
    "        \n",
    "        # Binary classification: HIGH (1) or LOW (0)\n",
    "        y.append(1 if future_avg > threshold else 0)\n",
    "    \n",
    "    return np.array(y)\n",
    "\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"üîß Building temporal features...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "WINDOW = 5\n",
    "HORIZON = 5\n",
    "THRESHOLD = 30.0  # CPU % threshold for HIGH frequency\n",
    "\n",
    "print(f\"\\nParameters:\")\n",
    "print(f\"   Lookback window: {WINDOW} samples ({WINDOW} seconds)\")\n",
    "print(f\"   Prediction horizon: {HORIZON} samples ({HORIZON} seconds ahead)\")\n",
    "print(f\"   CPU threshold: {THRESHOLD}%\")\n",
    "\n",
    "# Extract CPU values\n",
    "cpu_vals = df['cpu_percent'].values\n",
    "\n",
    "# Build features and labels\n",
    "X = build_temporal_features(cpu_vals, window=WINDOW)\n",
    "y = build_horizon_labels(cpu_vals, window=WINDOW, horizon=HORIZON, threshold=THRESHOLD)\n",
    "\n",
    "# Align X and y (y is shorter due to horizon)\n",
    "min_len = min(len(X), len(y))\n",
    "X = X[:min_len]\n",
    "y = y[:min_len]\n",
    "\n",
    "print(f\"\\n‚úÖ Feature engineering complete!\")\n",
    "print(f\"   Feature matrix shape: {X.shape}\")\n",
    "print(f\"   Label array shape: {y.shape}\")\n",
    "print(f\"   Features per sample: {X.shape[1]}\")\n",
    "\n",
    "print(f\"\\nüìä Class Distribution:\")\n",
    "n_high = y.sum()\n",
    "n_low = len(y) - n_high\n",
    "print(f\"   HIGH frequency (>30% CPU): {n_high:,} samples ({n_high/len(y)*100:.1f}%)\")\n",
    "print(f\"   LOW frequency (‚â§30% CPU): {n_low:,} samples ({n_low/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Show example features\n",
    "feature_names = [\n",
    "    'CPU_t-5', 'CPU_t-4', 'CPU_t-3', 'CPU_t-2', 'CPU_t-1',\n",
    "    'Delta_1', 'Delta_2', 'Delta_3', 'Delta_4',\n",
    "    'Mean', 'Std'\n",
    "]\n",
    "\n",
    "print(f\"\\nüìù Example Feature Vector:\")\n",
    "example_df = pd.DataFrame([X[1000]], columns=feature_names)\n",
    "print(example_df.T)\n",
    "print(f\"   Label: {'HIGH' if y[1000] == 1 else 'LOW'} frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0635ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temporal features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Temporal Feature Characteristics', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Feature correlations\n",
    "feature_df = pd.DataFrame(X, columns=feature_names)\n",
    "corr_matrix = feature_df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, ax=axes[0, 0], cbar_kws={'label': 'Correlation'})\n",
    "axes[0, 0].set_title('Feature Correlation Matrix', fontweight='bold')\n",
    "\n",
    "# Plot 2: Feature distributions by class\n",
    "axes[0, 1].hist(feature_df[y==0]['Mean'], bins=30, alpha=0.6, label='LOW freq', color='blue')\n",
    "axes[0, 1].hist(feature_df[y==1]['Mean'], bins=30, alpha=0.6, label='HIGH freq', color='red')\n",
    "axes[0, 1].set_title('CPU Mean Distribution by Frequency Class', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Average CPU (past 5 seconds)')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Delta distributions\n",
    "all_deltas = feature_df[['Delta_1', 'Delta_2', 'Delta_3', 'Delta_4']].values.flatten()\n",
    "axes[1, 0].hist(all_deltas, bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1, 0].set_title('CPU Rate of Change (Deltas)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Delta (% change per second)')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Std vs Mean (colored by class)\n",
    "sample_idx = np.random.choice(len(feature_df), min(5000, len(feature_df)), replace=False)\n",
    "scatter = axes[1, 1].scatter(feature_df.iloc[sample_idx]['Mean'], \n",
    "                            feature_df.iloc[sample_idx]['Std'],\n",
    "                            c=y[sample_idx], cmap='RdYlBu_r', alpha=0.5, s=10)\n",
    "axes[1, 1].set_title('CPU Variability vs Average (colored by label)', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Mean CPU (%)')\n",
    "axes[1, 1].set_ylabel('Std Dev CPU (%)')\n",
    "cbar = plt.colorbar(scatter, ax=axes[1, 1])\n",
    "cbar.set_label('Class (0=LOW, 1=HIGH)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('02_temporal_features.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üíæ Saved: 02_temporal_features.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b8526",
   "metadata": {},
   "source": [
    "## ü§ñ Part 4: Model Training (Random Forest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dfe60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ Training Smart-Watt ML Model...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Time-aware train/test split (NO SHUFFLE - preserve temporal order)\n",
    "split_idx = int(0.7 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"\\nüìä Dataset Split:\")\n",
    "print(f\"   Training samples: {len(X_train):,} ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"   Testing samples: {len(X_test):,} ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "print(f\"   Train HIGH ratio: {y_train.mean():.1%}\")\n",
    "print(f\"   Test HIGH ratio: {y_test.mean():.1%}\")\n",
    "\n",
    "# Smart-Watt Random Forest configuration\n",
    "print(f\"\\nüå≥ Model Configuration:\")\n",
    "print(f\"   Algorithm: Random Forest Classifier\")\n",
    "print(f\"   Number of trees: 400\")\n",
    "print(f\"   Max depth: 14\")\n",
    "print(f\"   Class weighting: Balanced (handles imbalance)\")\n",
    "print(f\"   Random state: 42 (reproducible)\")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=14,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(f\"\\n‚è≥ Training (this may take 1-2 minutes)...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"‚úÖ Training complete!\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_prob_all = model.predict_proba(X)[:, 1]  # Probability of HIGH class\n",
    "\n",
    "# Evaluate\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"MODEL PERFORMANCE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüìà Accuracy:\")\n",
    "print(f\"   Training: {train_acc*100:.2f}%\")\n",
    "print(f\"   Testing: {test_acc*100:.2f}%\")\n",
    "print(f\"   Difference: {abs(train_acc-test_acc)*100:.2f}% {'(slight overfit)' if train_acc > test_acc else '(good!)'}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(f\"\\nüìä Confusion Matrix (Test Set):\")\n",
    "print(f\"   True Negatives (LOW‚ÜíLOW): {cm[0,0]:,}\")\n",
    "print(f\"   False Positives (LOW‚ÜíHIGH): {cm[0,1]:,}\")\n",
    "print(f\"   False Negatives (HIGH‚ÜíLOW): {cm[1,0]:,}\")\n",
    "print(f\"   True Positives (HIGH‚ÜíHIGH): {cm[1,1]:,}\")\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nüìã Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, digits=3, target_names=['LOW', 'HIGH']))\n",
    "\n",
    "# Feature Importance\n",
    "importances = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nüîù Top 5 Most Important Features:\")\n",
    "for idx, row in importances.head().iterrows():\n",
    "    print(f\"   {row['Feature']:12s}: {row['Importance']:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model_path = 'smartwatt_synthetic_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"\\nüíæ Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f5b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Model Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0],\n",
    "            xticklabels=['LOW', 'HIGH'], yticklabels=['LOW', 'HIGH'])\n",
    "axes[0, 0].set_title(f'Confusion Matrix (Accuracy: {test_acc*100:.2f}%)', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('True Label')\n",
    "axes[0, 0].set_xlabel('Predicted Label')\n",
    "\n",
    "# Plot 2: Feature Importance\n",
    "importances.plot(kind='barh', x='Feature', y='Importance', ax=axes[0, 1], legend=False, color='steelblue')\n",
    "axes[0, 1].set_title('Feature Importance', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Importance Score')\n",
    "axes[0, 1].invert_yaxis()\n",
    "\n",
    "# Plot 3: Prediction Probability Distribution\n",
    "axes[1, 0].hist(y_prob_all[y==0], bins=50, alpha=0.6, label='True LOW', color='blue')\n",
    "axes[1, 0].hist(y_prob_all[y==1], bins=50, alpha=0.6, label='True HIGH', color='red')\n",
    "axes[1, 0].axvline(0.5, color='black', linestyle='--', linewidth=2, label='Decision Boundary')\n",
    "axes[1, 0].set_title('Prediction Probability Distribution', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Probability of HIGH Frequency')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Predictions over time (sample)\n",
    "sample_start = 5000\n",
    "sample_end = 5500\n",
    "time_range = range(sample_start, sample_end)\n",
    "axes[1, 1].plot(time_range, y[sample_start:sample_end], 'o-', label='True Label', \n",
    "                alpha=0.7, linewidth=2, markersize=4)\n",
    "axes[1, 1].plot(time_range, y_pred_test[sample_start-split_idx:sample_end-split_idx] \n",
    "                if sample_start >= split_idx else [None]*len(time_range), \n",
    "                's-', label='Predicted', alpha=0.7, linewidth=2, markersize=4)\n",
    "axes[1, 1].set_title('Predictions vs Ground Truth (Sample Window)', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Sample Index')\n",
    "axes[1, 1].set_ylabel('Frequency Class (0=LOW, 1=HIGH)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('03_model_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üíæ Saved: 03_model_performance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5feb4",
   "metadata": {},
   "source": [
    "## ‚ö° Part 5: DVFS Simulation (Smart-Watt Governor)\n",
    "\n",
    "Now we implement the actual frequency scaling logic with:\n",
    "- **Probability-aware decisions**: Use ML confidence\n",
    "- **Hysteresis**: Hold frequency to prevent oscillation\n",
    "- **Multi-level frequencies**: LOW/MID/HIGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdc6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartWattGovernor:\n",
    "    \"\"\"\n",
    "    Smart-Watt DVFS Governor with probability-aware decisions and hysteresis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, low_freq=1520, mid_freq=2000, high_freq=2400,\n",
    "                 hold_high=5, hold_low=3, window_cpu=5):\n",
    "        self.LOW_FREQ = low_freq\n",
    "        self.MID_FREQ = mid_freq\n",
    "        self.HIGH_FREQ = high_freq\n",
    "        self.HOLD_HIGH = hold_high\n",
    "        self.HOLD_LOW = hold_low\n",
    "        self.WINDOW_CPU = window_cpu\n",
    "        \n",
    "        # State\n",
    "        self.current_freq = None\n",
    "        self.hold_counter = 0\n",
    "        self.cpu_window = []\n",
    "    \n",
    "    def decide_frequency(self, cpu_util, prediction_prob):\n",
    "        \"\"\"\n",
    "        Decide target frequency based on CPU and ML prediction probability.\n",
    "        \n",
    "        Decision Logic:\n",
    "        - If prob > 85% AND recent CPU > 70%: HIGH freq\n",
    "        - Else if prob > 55%: MID freq\n",
    "        - Else: LOW freq\n",
    "        \n",
    "        Hysteresis prevents immediate transitions.\n",
    "        \"\"\"\n",
    "        # Update CPU window\n",
    "        self.cpu_window.append(cpu_util)\n",
    "        if len(self.cpu_window) > self.WINDOW_CPU:\n",
    "            self.cpu_window.pop(0)\n",
    "        \n",
    "        recent_cpu_mean = sum(self.cpu_window) / len(self.cpu_window)\n",
    "        \n",
    "        # Probability-aware decision\n",
    "        if prediction_prob > 0.85 and recent_cpu_mean > 70:\n",
    "            target_freq = self.HIGH_FREQ\n",
    "        elif prediction_prob > 0.55:\n",
    "            target_freq = self.MID_FREQ\n",
    "        else:\n",
    "            target_freq = self.LOW_FREQ\n",
    "        \n",
    "        # Initialize on first call\n",
    "        if self.current_freq is None:\n",
    "            self.current_freq = target_freq\n",
    "            self.hold_counter = self.HOLD_HIGH if target_freq == self.HIGH_FREQ else self.HOLD_LOW\n",
    "            return self.current_freq\n",
    "        \n",
    "        # Hysteresis: hold current frequency\n",
    "        if self.hold_counter > 0:\n",
    "            self.hold_counter -= 1\n",
    "            return self.current_freq\n",
    "        \n",
    "        # Allow transition\n",
    "        if target_freq != self.current_freq:\n",
    "            self.current_freq = target_freq\n",
    "            self.hold_counter = self.HOLD_HIGH if target_freq == self.HIGH_FREQ else self.HOLD_LOW\n",
    "        \n",
    "        return self.current_freq\n",
    "\n",
    "\n",
    "print(\"‚ö° Simulating Smart-Watt DVFS...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize governor\n",
    "governor = SmartWattGovernor()\n",
    "\n",
    "print(f\"\\nüéöÔ∏è Governor Configuration:\")\n",
    "print(f\"   LOW frequency: {governor.LOW_FREQ} MHz\")\n",
    "print(f\"   MID frequency: {governor.MID_FREQ} MHz\")\n",
    "print(f\"   HIGH frequency: {governor.HIGH_FREQ} MHz\")\n",
    "print(f\"   Hold HIGH: {governor.HOLD_HIGH} samples\")\n",
    "print(f\"   Hold LOW: {governor.HOLD_LOW} samples\")\n",
    "print(f\"   CPU averaging window: {governor.WINDOW_CPU} samples\")\n",
    "\n",
    "# Prepare simulation data\n",
    "df_sim = df.iloc[WINDOW:].copy().reset_index(drop=True)\n",
    "min_len = min(len(df_sim), len(y_prob_all))\n",
    "df_sim = df_sim.iloc[:min_len].copy()\n",
    "y_prob_sim = y_prob_all[:min_len]\n",
    "\n",
    "print(f\"\\nüìä Simulating {len(df_sim):,} samples (~{len(df_sim)/3600:.1f} hours)...\")\n",
    "\n",
    "# Run simulation\n",
    "smart_freqs = []\n",
    "for idx in range(len(df_sim)):\n",
    "    cpu_util = df_sim.iloc[idx]['cpu_percent']\n",
    "    prob = y_prob_sim[idx]\n",
    "    \n",
    "    freq = governor.decide_frequency(cpu_util, prob)\n",
    "    smart_freqs.append(freq)\n",
    "\n",
    "df_sim['smart_freq'] = smart_freqs\n",
    "df_sim['prediction_prob'] = y_prob_sim\n",
    "\n",
    "print(f\"‚úÖ Simulation complete!\")\n",
    "\n",
    "# Analysis\n",
    "freq_counts = df_sim['smart_freq'].value_counts().sort_index(ascending=False)\n",
    "freq_transitions = (df_sim['smart_freq'].diff().abs() > 0).sum()\n",
    "\n",
    "print(f\"\\nüìä Frequency Usage:\")\n",
    "for freq, count in freq_counts.items():\n",
    "    pct = count / len(df_sim) * 100\n",
    "    print(f\"   {freq} MHz: {count:,} samples ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüîÑ Frequency Transitions: {freq_transitions:,} ({freq_transitions/len(df_sim)*100:.3f}% of samples)\")\n",
    "print(f\"   Average: {freq_transitions/(len(df_sim)/3600):.1f} transitions per hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37260f00",
   "metadata": {},
   "source": [
    "## üîã Part 6: Energy Modeling (Physics-Based)\n",
    "\n",
    "Energy consumption model:  \n",
    "**E = f¬≤ + Œ±¬∑|Œîf|¬∑f**\n",
    "\n",
    "Where:\n",
    "- **f¬≤**: Base power (frequency squared - CMOS power law)\n",
    "- **Œ±¬∑|Œîf|¬∑f**: Transition penalty (cost of frequency changes)\n",
    "- **Œ± = 0.5**: Transition penalty coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîã Calculating Energy Consumption...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "ALPHA = 0.5  # Transition penalty coefficient\n",
    "LOGICAL_CORES = 8\n",
    "\n",
    "# Frequency deltas\n",
    "df_sim['freq_delta'] = df_sim['smart_freq'].diff().abs().fillna(0)\n",
    "\n",
    "# Core utilization (scale energy by active cores)\n",
    "active_ratio = np.minimum(1.0, df_sim['process_count'] / LOGICAL_CORES)\n",
    "\n",
    "# Physics-based energy model\n",
    "df_sim['smart_energy'] = (\n",
    "    df_sim['smart_freq'] ** 2  # Base power\n",
    "    + ALPHA * df_sim['freq_delta'] * df_sim['smart_freq']  # Transition cost\n",
    ") * active_ratio  # Scale by active cores\n",
    "\n",
    "total_energy_smart = df_sim['smart_energy'].sum()\n",
    "\n",
    "print(f\"\\n‚ö° Energy Model:\")\n",
    "print(f\"   Formula: E = f¬≤ + Œ±¬∑|Œîf|¬∑f\")\n",
    "print(f\"   Transition penalty (Œ±): {ALPHA}\")\n",
    "print(f\"   Core scaling: Active cores / {LOGICAL_CORES}\")\n",
    "\n",
    "print(f\"\\nüìä Smart-Watt Energy Consumption:\")\n",
    "print(f\"   Total energy: {total_energy_smart:,.0f} (arbitrary units)\")\n",
    "print(f\"   Average per sample: {total_energy_smart/len(df_sim):,.2f}\")\n",
    "print(f\"   Average per hour: {total_energy_smart/(len(df_sim)/3600):,.0f}\")\n",
    "\n",
    "# Energy breakdown by frequency\n",
    "print(f\"\\nüîã Energy by Frequency Level:\")\n",
    "for freq in sorted(df_sim['smart_freq'].unique(), reverse=True):\n",
    "    mask = df_sim['smart_freq'] == freq\n",
    "    freq_energy = df_sim[mask]['smart_energy'].sum()\n",
    "    freq_pct = freq_energy / total_energy_smart * 100\n",
    "    print(f\"   {freq} MHz: {freq_energy:,.0f} ({freq_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e008de",
   "metadata": {},
   "source": [
    "## üìä Part 7: Baseline DVFS Comparison\n",
    "\n",
    "Compare Smart-Watt against a traditional threshold-based DVFS:\n",
    "- **Baseline**: If CPU > 30%, use HIGH (2400 MHz), else LOW (1520 MHz)\n",
    "- **Smart-Watt**: ML-based with probability awareness and hysteresis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Baseline DVFS Comparison...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Baseline: Simple threshold-based DVFS\n",
    "print(f\"\\nüîß Baseline Governor:\")\n",
    "print(f\"   Logic: If CPU > 30%, use HIGH (2400 MHz), else LOW (1520 MHz)\")\n",
    "print(f\"   No hysteresis, no ML, no MID frequency\")\n",
    "\n",
    "baseline_freqs = np.where(df_sim['cpu_percent'] > 30, 2400, 1520)\n",
    "df_sim['baseline_freq'] = baseline_freqs\n",
    "df_sim['baseline_freq_delta'] = df_sim['baseline_freq'].diff().abs().fillna(0)\n",
    "\n",
    "# Calculate baseline energy\n",
    "df_sim['baseline_energy'] = (\n",
    "    df_sim['baseline_freq'] ** 2\n",
    "    + ALPHA * df_sim['baseline_freq_delta'] * df_sim['baseline_freq']\n",
    ") * active_ratio\n",
    "\n",
    "total_energy_baseline = df_sim['baseline_energy'].sum()\n",
    "baseline_transitions = (df_sim['baseline_freq_delta'] > 0).sum()\n",
    "\n",
    "print(f\"\\nüìä Baseline Results:\")\n",
    "print(f\"   Total energy: {total_energy_baseline:,.0f}\")\n",
    "print(f\"   Frequency transitions: {baseline_transitions:,}\")\n",
    "\n",
    "# Calculate savings\n",
    "energy_savings = (total_energy_baseline - total_energy_smart) / total_energy_baseline * 100\n",
    "transition_reduction = (baseline_transitions - freq_transitions) / baseline_transitions * 100\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üí∞ SMART-WATT vs BASELINE COMPARISON\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Total Energy', 'Avg Energy/Sample', 'Transitions', 'Transitions/Sample'],\n",
    "    'Baseline': [\n",
    "        f\"{total_energy_baseline:,.0f}\",\n",
    "        f\"{total_energy_baseline/len(df_sim):,.2f}\",\n",
    "        f\"{baseline_transitions:,}\",\n",
    "        f\"{baseline_transitions/len(df_sim):.4f}\"\n",
    "    ],\n",
    "    'Smart-Watt': [\n",
    "        f\"{total_energy_smart:,.0f}\",\n",
    "        f\"{total_energy_smart/len(df_sim):,.2f}\",\n",
    "        f\"{freq_transitions:,}\",\n",
    "        f\"{freq_transitions/len(df_sim):.4f}\"\n",
    "    ],\n",
    "    'Improvement': [\n",
    "        f\"{energy_savings:+.2f}%\",\n",
    "        f\"{energy_savings:+.2f}%\",\n",
    "        f\"{transition_reduction:+.1f}%\",\n",
    "        f\"{transition_reduction:+.1f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison.to_string(index=False))\n",
    "\n",
    "print(f\"\\nüéØ Key Results:\")\n",
    "if energy_savings > 0:\n",
    "    print(f\"   ‚úÖ Energy savings: {energy_savings:.2f}%\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Energy increase: {abs(energy_savings):.2f}%\")\n",
    "\n",
    "if transition_reduction > 0:\n",
    "    print(f\"   ‚úÖ Transition reduction: {transition_reduction:.1f}%\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  More transitions: {abs(transition_reduction):.1f}%\")\n",
    "\n",
    "# Save comparison\n",
    "comparison.to_csv('dvfs_comparison_results.csv', index=False)\n",
    "print(f\"\\nüíæ Saved: dvfs_comparison_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33602bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Smart-Watt vs Baseline DVFS Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "sample_range_viz = min(3600, len(df_sim))  # Show 1 hour\n",
    "\n",
    "# Plot 1: Frequency decisions\n",
    "axes[0, 0].plot(df_sim['baseline_freq'][:sample_range_viz], \n",
    "                linewidth=1.5, alpha=0.7, label='Baseline', color='red')\n",
    "axes[0, 0].plot(df_sim['smart_freq'][:sample_range_viz], \n",
    "                linewidth=1.5, alpha=0.7, label='Smart-Watt', color='green')\n",
    "axes[0, 0].set_title('Frequency Decisions (First Hour)', fontweight='bold', fontsize=12)\n",
    "axes[0, 0].set_xlabel('Time (seconds)')\n",
    "axes[0, 0].set_ylabel('CPU Frequency (MHz)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Energy consumption over time\n",
    "axes[0, 1].plot(df_sim['baseline_energy'][:sample_range_viz].cumsum(), \n",
    "                linewidth=2, alpha=0.8, label='Baseline', color='red')\n",
    "axes[0, 1].plot(df_sim['smart_energy'][:sample_range_viz].cumsum(), \n",
    "                linewidth=2, alpha=0.8, label='Smart-Watt', color='green')\n",
    "axes[0, 1].set_title('Cumulative Energy Consumption', fontweight='bold', fontsize=12)\n",
    "axes[0, 1].set_xlabel('Time (seconds)')\n",
    "axes[0, 1].set_ylabel('Cumulative Energy (arbitrary units)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Frequency distribution\n",
    "x_pos = np.arange(2)\n",
    "baseline_dist = df_sim['baseline_freq'].value_counts(normalize=True).sort_index(ascending=False)\n",
    "smart_dist = df_sim['smart_freq'].value_counts(normalize=True).sort_index(ascending=False)\n",
    "\n",
    "width = 0.35\n",
    "axes[1, 0].bar(x_pos - width/2, [baseline_dist.get(2400, 0), baseline_dist.get(1520, 0)], \n",
    "               width, label='Baseline', color='red', alpha=0.7)\n",
    "axes[1, 0].bar(x_pos + width/2, \n",
    "               [smart_dist.get(2400, 0), smart_dist.get(2000, 0) + smart_dist.get(1520, 0)],\n",
    "               width, label='Smart-Watt', color='green', alpha=0.7)\n",
    "axes[1, 0].set_title('Frequency Usage Distribution', fontweight='bold', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Proportion of Time')\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(['HIGH', 'LOW/MID'])\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Comparison metrics\n",
    "metrics = ['Energy\\nSavings', 'Transition\\nReduction']\n",
    "values = [energy_savings, transition_reduction]\n",
    "colors = ['green' if v > 0 else 'red' for v in values]\n",
    "\n",
    "bars = axes[1, 1].bar(metrics, values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "axes[1, 1].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "axes[1, 1].set_title('Smart-Watt Improvements over Baseline', fontweight='bold', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Improvement (%)')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, val in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{val:+.1f}%', ha='center', va='bottom' if height > 0 else 'top',\n",
    "                    fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('04_baseline_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üíæ Saved: 04_baseline_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef9e4c",
   "metadata": {},
   "source": [
    "## üìã Part 8: Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e62c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SMART-WATT DVFS: FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"   Total samples: {len(df):,}\")\n",
    "print(f\"   Duration: {len(df)/3600:.1f} hours\")\n",
    "print(f\"   Features used: {X.shape[1]} temporal features\")\n",
    "\n",
    "print(f\"\\nü§ñ Model Performance:\")\n",
    "print(f\"   Algorithm: Random Forest (400 trees)\")\n",
    "print(f\"   Training accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"   Testing accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"   Top feature: {importances.iloc[0]['Feature']} (importance: {importances.iloc[0]['Importance']:.3f})\")\n",
    "\n",
    "print(f\"\\n‚ö° DVFS Simulation:\")\n",
    "print(f\"   Samples simulated: {len(df_sim):,}\")\n",
    "print(f\"   Frequency levels used: {len(df_sim['smart_freq'].unique())}\")\n",
    "print(f\"   Total transitions: {freq_transitions:,}\")\n",
    "print(f\"   Transition rate: {freq_transitions/len(df_sim)*100:.3f}%\")\n",
    "\n",
    "print(f\"\\nüí∞ Energy Savings:\")\n",
    "print(f\"   Baseline energy: {total_energy_baseline:,.0f}\")\n",
    "print(f\"   Smart-Watt energy: {total_energy_smart:,.0f}\")\n",
    "print(f\"   Energy savings: {energy_savings:.2f}%\" if energy_savings > 0 else f\"   Energy increase: {abs(energy_savings):.2f}%\")\n",
    "print(f\"   Transition reduction: {transition_reduction:.1f}%\" if transition_reduction > 0 else f\"   More transitions: {abs(transition_reduction):.1f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Key Achievements:\")\n",
    "achievements = [\n",
    "    \"Implemented temporal windowing (5 samples ‚Üí 11 features)\",\n",
    "    \"Achieved horizon-based prediction (1 second ahead)\",\n",
    "    f\"Trained high-accuracy model ({test_acc*100:.1f}%)\",\n",
    "    \"Implemented probability-aware DVFS decisions\",\n",
    "    \"Added hysteresis to prevent oscillation\",\n",
    "    \"Used multi-level frequencies (LOW/MID/HIGH)\",\n",
    "    \"Applied physics-based energy modeling\",\n",
    "    f\"Demonstrated {'energy savings' if energy_savings > 0 else 'methodology'} vs baseline\"\n",
    "]\n",
    "for i, achievement in enumerate(achievements, 1):\n",
    "    print(f\"   {i}. {achievement}\")\n",
    "\n",
    "print(f\"\\nüéØ Conclusions:\")\n",
    "if test_acc > 0.90 and energy_savings > 0:\n",
    "    print(f\"   ‚úÖ Smart-Watt successfully demonstrates ML-based DVFS\")\n",
    "    print(f\"   ‚úÖ Achieves {energy_savings:.1f}% energy savings with {transition_reduction:.0f}% fewer transitions\")\n",
    "    print(f\"   ‚úÖ High model accuracy ({test_acc*100:.1f}%) indicates good predictability\")\n",
    "elif test_acc > 0.90:\n",
    "    print(f\"   ‚úÖ High model accuracy ({test_acc*100:.1f}%) demonstrates predictability\")\n",
    "    print(f\"   ‚ÑπÔ∏è  Energy results depend on workload characteristics\")\n",
    "    print(f\"   ‚úÖ Reduced transitions ({transition_reduction:.0f}%) improves stability\")\n",
    "else:\n",
    "    print(f\"   ‚ÑπÔ∏è  Model accuracy: {test_acc*100:.1f}%\")\n",
    "    print(f\"   ‚ÑπÔ∏è  Methodology validated, results vary by workload\")\n",
    "\n",
    "print(f\"\\nüìÅ Generated Files:\")\n",
    "files = [\n",
    "    \"01_raw_data_analysis.png\",\n",
    "    \"02_temporal_features.png\",\n",
    "    \"03_model_performance.png\",\n",
    "    \"04_baseline_comparison.png\",\n",
    "    \"dvfs_comparison_results.csv\",\n",
    "    \"smartwatt_synthetic_model.pkl\"\n",
    "]\n",
    "for file in files:\n",
    "    print(f\"   üìÑ {file}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b54bf",
   "metadata": {},
   "source": [
    "## üì• Download Results\n",
    "\n",
    "If running on Google Colab, download all generated files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if using Google Colab\n",
    "# from google.colab import files\n",
    "\n",
    "# download_files = [\n",
    "#     '01_raw_data_analysis.png',\n",
    "#     '02_temporal_features.png',\n",
    "#     '03_model_performance.png',\n",
    "#     '04_baseline_comparison.png',\n",
    "#     'dvfs_comparison_results.csv',\n",
    "#     'smartwatt_synthetic_model.pkl'\n",
    "# ]\n",
    "\n",
    "# for file in download_files:\n",
    "#     try:\n",
    "#         files.download(file)\n",
    "#         print(f\"‚úÖ Downloaded: {file}\")\n",
    "#     except:\n",
    "#         print(f\"‚ö†Ô∏è  Could not download: {file}\")\n",
    "\n",
    "print(\"üì• All results saved to current directory\")\n",
    "print(\"   Use these files in your project report!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764f9dfb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Appendix: Technical Details\n",
    "\n",
    "### Implemented Features Summary\n",
    "\n",
    "1. **Temporal Windowing**: Transforms single CPU value into 11 features capturing history and trends\n",
    "2. **Horizon Prediction**: Predicts future CPU load (1 second ahead) instead of current state\n",
    "3. **Random Forest Classifier**: 400 decision trees with balanced class weights\n",
    "4. **Probability-Aware DVFS**: Uses ML confidence scores for frequency decisions\n",
    "5. **Hysteresis**: Prevents ping-pong by holding frequencies (HOLD_HIGH=5, HOLD_LOW=3)\n",
    "6. **Multi-Level Frequencies**: LOW (1520), MID (2000), HIGH (2400 MHz) for granular control\n",
    "7. **Physics-Based Energy**: E = f¬≤ + Œ±¬∑|Œîf|¬∑f accounts for base power and transition costs\n",
    "8. **Baseline Comparison**: Quantifies improvement over traditional threshold-based DVFS\n",
    "\n",
    "### Key Innovations\n",
    "\n",
    "- **Predictive, not Reactive**: Scales frequency BEFORE load increases\n",
    "- **Temporal Context**: Uses past behavior, not just current state\n",
    "- **Stability**: Hysteresis prevents unnecessary frequency changes\n",
    "- **Realistic Energy Model**: Accounts for transition costs, not just steady-state power\n",
    "\n",
    "### Use in Report\n",
    "\n",
    "This notebook demonstrates the **methodology and implementation** of Smart-Watt DVFS.\n",
    "For discussion of **real-world challenges** (OS differences, threshold sensitivity), \n",
    "see the Windows/Ubuntu comparison analysis.\n",
    "\n",
    "---\n",
    "\n",
    "**Created**: February 2026  \n",
    "**Framework**: Smart-Watt Predictive DVFS  \n",
    "**Dataset**: Synthetic laptop data (24 hours)  \n",
    "**Purpose**: ML-based CPU power optimization"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
